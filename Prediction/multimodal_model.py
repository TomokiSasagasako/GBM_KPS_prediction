# -*- coding: utf-8 -*-
"""MultimodalModel

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15pdn81YOduRd53j_2K8yN4mf4RRuv5PL

# Mount the drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Setting features"""

import pandas as pd
import tensorflow as tf
import numpy as np
import random
import os
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RepeatedStratifiedKFold
from grouped_permutation_importance import grouped_permutation_importance
from tensorflow.keras.backend import clear_session
from scikeras.wrappers import KerasClassifier, KerasRegressor
import warnings
warnings.filterwarnings('ignore')

df_analysis = pd.read_csv('patients_data.csv')
print('Analyze {} cases'.format(len(df_analysis)))

#Object variables
ls_targetcolumns = ['KPS_less70']

#Clinical parameters
ls_clinical = [#'patient_id',#'gene_IDH_mut',
          'sex','age_at_diagnosis',
          'dexterity','symptom_preoperative_speechlessness',
          'symptom_preoperative_focal_sign', 'symptom_preoperative_palsy',
          'symptom_epilepsy', 'KPS_preope',
          #Intraoperative variables
          'ope_monitoring','ope_5ALA',
          'ope_awake', 'ope_PDT',
          'ope_GLIADEL','ope_resection_classification',##biopsy or tumor removal
          #Immunohistochemical and genetic variables
          'IHC_MGMT','IHC_MIB1',
          'gene_MGMT_met', 'gene_TERTp',
          #Postoperative variables
          'RT_radiation_dose', 'RT_fractionation',
          'chemo_BEV', 'chemo_TMZ',
          #Image findings
          'image_necrosis', 'image_laterality', 'image_ependymal_invasion',
          'image_midline_shift', 'image_corpus_callosum_invasion',
          'Extent of resection'
                     ]

#MRI features
ls_imgfeat = (df_analysis.columns.tolist()['MRI features columns'])
#Clinical parameters + MRI features
ls_clinical_imgfinding_imgfeat = (ls_clinical + ls_imgfeat)

import pandas as pd
import tensorflow as tf
import numpy as np

#Objective variable
ls_targetcolumns = ['KPS_less70']

#Explanatory variables
df_clinical_imgfinding_imgfeat = df_analysis.loc[:, (ls_clinical_imgfinding_imgfeat + ls_targetcolumns)]

#drop_col = ['KPS_worsening']
drop_col = ['KPS_less70']

X = df_clinical_imgfinding_imgfeat.drop(drop_col, axis=1)
y = df_clinical_imgfinding_imgfeat['KPS_less70']

X1 = X.loc[:, ls_imgfeat].values
X2 = X.loc[:, ls_clinical].values
y = tf.keras.utils.to_categorical(y, num_classes=2)

"""# Multimodal model"""

def create_model():
    input1 = tf.keras.Input(shape=(196,))
    input2 = tf.keras.Input(shape=(28,))
    x = tf.keras.layers.Dense(24, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(input1)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dense(6, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dense(2, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Concatenate()([x, input2])
    x = tf.keras.layers.Dense(196, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dense(144, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dense(96, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dense(24, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dense(12, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dense(6, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
    x = tf.keras.layers.LayerNormalization()(x)
    output =  tf.keras.layers.Dense(2, activation='softmax')(x)
    model = tf.keras.Model(inputs=[input1, input2], outputs=output, name="brainclassifier")

    model.compile(
        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
        metrics=[tf.keras.metrics.CategoricalAccuracy(name="accuracy"), tf.keras.metrics.AUC(name="AUC")]
    )

    return model

"""## Repeat Kfold Cross Validation"""

n_epochs = 20

nn_k_folds = 5

n_repeats = 10

# Illustrate ROC curve

def plot_roc_curve(fprs, tprs, auc_scores):
    """Plot the ROC curve for k-folds and average AUC"""
    plt.figure(figsize=(10, 6))

    # Plot the ROC curve for each fold  ## 各foldのROC curveを描画したいとき
    for i, (fpr, tpr) in enumerate(zip(fprs, tprs_interpolated)):
        #plt.plot(fpr, tpr, lw=2, label=f'ROC Fold {i+1} (AUC = {auc_scores[i]:.4f})') ##各fold ROCカーブ（カラー)
        plt.plot(fpr, tpr, linestyle = ':', color='grey',lw=2) ##各fold ROCカーブ(グレイ)

    # Plot the average ROC and AUC score
    mean_tpr = np.mean(tprs_interpolated, axis=0)
    mean_auc = np.mean(auc_scores)
    plt.plot(base_fpr, mean_tpr, color='b', linestyle='-',
             label=f'Mean ROC (AUC = {mean_auc:.3f})', lw=2)

    # Plotting the guessing line
    plt.plot([0, 1], [0, 1], color='r', lw=2, linestyle='--')  # diagonal line
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    #plt.title('Receiver Operating Characteristic (ROC) Curve for {}-folds'.format(k_folds))
    plt.legend(loc="lower right")
    plt.show()

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np
from sklearn.svm import SVC
from scipy import interp
import pandas as pd
import tensorflow as tf
import numpy as np
import random
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RepeatedStratifiedKFold
from tensorflow.keras.backend import clear_session
from scikeras.wrappers import KerasClassifier, KerasRegressor
import warnings
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, f1_score, average_precision_score
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold


warnings.filterwarnings('ignore')
random_seed = 42

# Initialize random seed for reproducibility
def set_seed(seed):
   # Set seed for TensorFlow, NumPy, and Python random
    tf.random.set_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)

set_seed(random_seed)
auc_scores = []  # Stores AUC scores for each fold

def interpolate_tpr(fpr, tpr, base_fpr):
    """
    Interpolate the given TPR values to be consistent with the base_fpr values.
    """
    return np.interp(base_fpr, fpr, tpr)


# Initialize lists to store metrics for each repeat
all_fprs = []
all_tprs = []
all_auc_scores = []

all_repeat_auc_scores = []
all_repeat_accuracies = []
all_repeat_specificities = []
all_repeat_sensitivities = []
all_repeat_f1_scores = []

y_stratified = np.argmax(y, axis=1)

for r in range(n_repeats):
    #Change seed for each repeat
    print(f"\n----- Repeat: {r+1} -----\n")
    kfold = StratifiedKFold(n_splits=nn_k_folds, shuffle=True, random_state=r)  # 繰り返し毎にシードを変更

    # Initialize the lists for the metrics
    fprs = []
    tprs_interpolated = []
    mean_fpr = np.linspace(0, 1, 100)
    all_histories = []
    all_auc_scores = []
    all_accuracies = []
    all_specificities = []
    all_sensitivities = []
    all_f1_scores = []

    # Loop over each fold in the stratified k-fold
    for train_idx, val_idx in kfold.split(X, y_stratified):
        X1_train, X1_val = X1[train_idx], X1[val_idx]
        X2_train, X2_val = X2[train_idx], X2[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # Reset the model&create new model instance
        clear_session()
        model = create_model()

        # Train the model
        history = model.fit(
            [X1_train, X2_train], y_train,
            batch_size=16,
            epochs=n_epochs,
            validation_data=([X1_val, X2_val], y_val),
            shuffle=True
        )
        all_histories.append(history)

        # Validation prediction for this fold
        y_pred_val = model.predict([X1_val, X2_val], batch_size=16)
        y_pred_binary = y_pred_val[:, 1]
        fpr, tpr, _ = roc_curve(y_val[:, 1], y_pred_binary)
        # Compute the ROC curve and interpolate the TPR
        tpr_interpolated = interp(mean_fpr, fpr, tpr)
        tpr_interpolated[0] = 0.0
        tprs_interpolated.append(tpr_interpolated)

        # Calculate and store ROC curve and AUC for this fold
        roc_auc = auc(fpr, tpr)
        all_auc_scores.append(roc_auc)

        # Calculate metrics
        y_true = np.argmax(y_val, axis=1)
        y_pred = np.argmax(y_pred_val, axis=1)

        # Compute the other metrics
        conf_mat = confusion_matrix(y_true, y_pred)
        TN, FP, FN, TP = conf_mat.ravel()
        accuracy = accuracy_score(y_true, y_pred)
        specificity = TN / (TN + FP)
        sensitivity = TP / (TP + FN)
        f1 = f1_score(y_true, y_pred)

        # Add the metrics to their respective lists
        all_accuracies.append(accuracy)
        all_specificities.append(specificity)
        all_sensitivities.append(sensitivity)
        all_f1_scores.append(f1)

        del model
        tf.keras.backend.clear_session


    # Calculate mean AUC across all repeats
    mean_tpr = np.mean(tprs_interpolated, axis=0)
    mean_tpr[-1] = 1.0
    all_tprs.append(mean_tpr)
    all_fprs.append(mean_fpr)
    all_repeat_auc_scores.append(np.mean(all_auc_scores))
    all_repeat_accuracies.append(np.mean(all_accuracies))
    all_repeat_specificities.append(np.mean(all_specificities))
    all_repeat_sensitivities.append(np.mean(all_sensitivities))
    all_repeat_f1_scores.append(np.mean(all_f1_scores))

# Calcurate the auc
mean_tpr_final = np.mean(all_tprs, axis=0)
mean_auc = auc(mean_fpr, mean_tpr_final)

# Illustrating the plot
plt.figure(figsize=(10, 8))
plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)
plt.plot(mean_fpr, mean_tpr_final, color='b',
         label=r'Mean ROC (AUC = %0.3f )' % (mean_auc),
         lw=2, alpha=.8)

# Plot ROC curve and individual repeats
for i in range(n_repeats):
    plt.plot(all_fprs[i], all_tprs[i], lw=1, alpha=0.3, color='grey')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve after 10 repeats')
plt.legend(loc="lower right")
plt.show()

# Calcurate final metrics and their standard deviation
mean_accuracy = np.mean(all_repeat_accuracies)
std_accuracy = np.std(all_repeat_accuracies)

mean_specificity = np.mean(all_repeat_specificities)
std_specificity = np.std(all_repeat_specificities)

mean_sensitivity = np.mean(all_repeat_sensitivities)
std_sensitivity = np.std(all_repeat_sensitivities)

mean_f1 = np.mean(all_repeat_f1_scores)
std_f1 = np.std(all_repeat_f1_scores)

mean_repeat_auc = np.mean(all_repeat_auc_scores)
std_repeat_auc = np.std(all_repeat_auc_scores)

# Display overall metrics across all repeats and folds

print(f"\nOverall Mean AUC across all repeats and folds: {mean_repeat_auc:.3f}")
print('All AUC:', all_repeat_auc_scores)
print(f"Standard Deviation of AUC across all repeats and folds: {std_repeat_auc:.3f}")

print(f"\nOverall Mean and Std Dev Metrics across all repeats and folds:")
print(f"Accuracy: {mean_accuracy:.3f} ± {std_accuracy:.3f}")
print('All Accuracieas:', all_repeat_accuracies)

print(f"Specificity:    {mean_specificity:.3f} ± {std_specificity:.3f}")
print('All Specificitieas:',  all_repeat_specificities)

print(f"Sensitivity:    {mean_sensitivity:.3f} ± {std_sensitivity:.3f}")
print('All Sensitivity:', all_repeat_sensitivities)

print(f"F1 Score:       {mean_f1:.3f} ± {std_f1:.3f}")
print('All F1 score:', all_repeat_f1_scores)